default:

  # the random seed
  seed: 0
  # the number of parallel environments
  num_envs: 16
  # the maximum length of an episode
  max_episode_length: 1000

  # *------------------------------- training -------------------------------* #
  # number of epochs
  num_epochs: 500
  # number of training steps per epoch to roll out training batch
  num_training_steps_per_epoch: 64
  # evaluation frequency
  eval_frequency: 1

  # learning rate for the optimizer
  learning_rate: 0.001
  # short horizon to compute the gradient
  short_horizon: 16
  # the maximum norm of the gradient for clipping
  max_grad_norm: 10

  # number of updates using the same batch
  num_updates_per_step: 4
  # size of each minibatch
  minibatch_size: 16
  # reward scaling
  reward_scaling: 10.0
  cost_scaling: 1.0
  # gae lambda
  gae_lambda: 0.95
  # discounting factor
  discount_gamma: 0.99

  # *----------------------------- actor network ----------------------------* #
  actor_config:
    # the hidden layer sizes for the actor network
    hidden_layer_sizes: [64, 64]
    # the activation function for the actor network
    activation: relu

  # *---------------------------- critic network ----------------------------* #
  critic_config:
    # the hidden layer sizes for the critic network
    hidden_layer_sizes: [64, 64]
    # the activation function for the critic network
    activation: relu

  #*---------------------------- lagrangian ----------------------------------*#
  lagrangian_multiplier: 0.000
  lagrangian_learning: 0.003
  cost_limit_grad: 0.25
  multiplier_lr: 0.003
  threshold: 200.0
